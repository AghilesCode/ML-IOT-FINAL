# -*- coding: utf-8 -*-
"""final_result.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k-gw0Cfw0Y-noGnoszmIk9UUjX9SqKJk
"""

import speech_recognition as sr
from pydub import AudioSegment
import os

def m4a_to_wav(m4a_file_path):
    # Load the M4A file
    audio = AudioSegment.from_file(m4a_file_path, format='m4a')
    # Export to WAV
    wav_file_path = m4a_file_path.replace('.m4a', '.wav')
    audio.export(wav_file_path, format='wav')
    return wav_file_path

def convert_audio_to_text(audio_file_path):
    # Convert M4A to WAV for compatibility
    wav_file_path = m4a_to_wav(audio_file_path)

    # Initialize recognizer
    recognizer = sr.Recognizer()

    with sr.AudioFile(wav_file_path) as source:
        # Listen for the data (load audio to memory)
        audio_data = recognizer.record(source)

        # Essayer de reconnaître en anglais
        try:
            text = recognizer.recognize_google(audio_data, language='en-US')
            return text
        except (sr.UnknownValueError, sr.RequestError):
            pass  # Ignorer si la reconnaissance en anglais échoue

        # Essayer de reconnaître en français si l'anglais échoue
        try:
            text = recognizer.recognize_google(audio_data, language='fr-FR')
            return text
        except (sr.UnknownValueError, sr.RequestError):
            pass  # Ignorer si la reconnaissance en français échoue également

"""Example usage
audio_file = "test_audio_fr.mp3"
fr = convert_audio_to_text(audio_file)
print('fr: ',fr)

audio_file = "test_audio_eng.mp3"
eng = convert_audio_to_text(audio_file)
print('eng: ',eng)
"""
import cv2
import numpy as np

def detect_and_crop_screen(image_path):
    # Charger l'image
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blur, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    # Filtrer les contours par aire pour ignorer les petits objets
    contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 1000]  # Ajustez 1000 au besoin

    cropped_images = []  # Liste pour stocker les images découpées

    for cnt in contours:
        epsilon = 0.05 * cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, epsilon, True)
        if len(approx) == 4:
            cv2.drawContours(img, [approx], 0, (0, 255, 0), 4)
            # Calculer le rectangle englobant et découper l'écran
            x, y, w, h = cv2.boundingRect(approx)
            cropped_img = img[y:y+h, x:x+w]
            cropped_images.append(cropped_img)

    # Sauvegarder l'image recadrée en écrasant le fichier d'origine
    cv2.imwrite(image_path, cropped_images[0])
"""
# Chemin de l'image
image_path = 'C:/Users/aanis/Desktop/P03/PAS PROJET/ml_iot_project/test_pc.png'

# Détecter et recadrer l'écran, puis écraser le fichier d'origine
detect_and_crop_screen(image_path)
"""
import pytesseract
from PIL import Image
import re

# Définir une liste de mots inutiles (stop words) en français
stop_words = set([
    "le", "la", "les", "un", "une", "de", "des", "du", "et", "à", "au", "aux", "en", "dans", "avec", "pour", "sur", "par",
    "je", "tu", "il", "elle", "nous", "vous", "ils", "elles", "ce", "cet", "cette", "ces", "mon", "ton", "son", "ma", "ta",
    "sa", "notre", "votre", "leur", "mes", "tes", "ses", "nos", "vos", "leurs", "qui", "que", "quoi", "dont", "où",
    "si", "mais", "ou", "et", "donc", "or", "ni", "car"
])

# Chemin vers l'exécutable tesseract. À modifier selon votre installation.
pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'

def extract_filter_and_remove_duplicates(image_path):
    try:
        # Ouverture de l'image
        img = Image.open(image_path)

        # Utilisation de pytesseract pour extraire le texte
        text = pytesseract.image_to_string(img)

        # Filtrer pour ne garder que les mots ayant du sens
        filtered_text = re.sub(r'[^\w\s]', '', text)
        words = filtered_text.split()

        # Suppression des mots inutiles et des doublons
        filtered_words = [word.lower() for word in words if word.lower() not in stop_words]
        unique_words = list(set(filtered_words))  # Enlève les doublons

        return " ".join(unique_words)
    except Exception as e:
        return f"Erreur lors de l'extraction, du filtrage et de la suppression des doublons : {str(e)}"

if __name__ == "__main__":
    image_path = 'image_text.jpg'  # Mettez ici le chemin vers votre image
    result_text = extract_filter_and_remove_duplicates(image_path)
    print(result_text)

import string
import nltk
from nltk.corpus import wordnet as wn
from collections import Counter

# Fonction de nettoyage et lemmatisation du texte
def nettoyer_et_lemmatiser_texte(texte):
    lemmatizer = nltk.WordNetLemmatizer()
    texte_sans_ponctuation = texte.translate(str.maketrans('', '', string.punctuation))
    mots = nltk.word_tokenize(texte_sans_ponctuation.lower())
    mots_lemmatises = [lemmatizer.lemmatize(mot) for mot in mots]
    return mots_lemmatises

# Fonction pour trouver des synonymes en utilisant NLTK
def trouver_synonymes(mot):
    synonymes = set()
    for syn in wn.synsets(mot):
        for lemma in syn.lemmas():
            synonymes.add(lemma.name())
    return synonymes

# Fonction améliorée pour comparer deux textes
def comparer_textes_ameliore(texte1, texte2, seuil_triche=20):
    mots_texte1 = nettoyer_et_lemmatiser_texte(texte1)
    mots_texte2 = nettoyer_et_lemmatiser_texte(texte2)

    poids_texte1 = Counter(mots_texte1)
    poids_texte2 = Counter(mots_texte2)

    # Calculer les ensembles de synonymes pour chaque mot
    mots_avec_synonymes1 = {mot: trouver_synonymes(mot) for mot in poids_texte1}
    mots_avec_synonymes2 = {mot: trouver_synonymes(mot) for mot in poids_texte2}

    mots_communs_avec_poids = 0
    total_poids = sum(poids_texte1.values()) + sum(poids_texte2.values())

    for mot, poids in poids_texte1.items():
        if mot in poids_texte2:
            mots_communs_avec_poids += (poids + poids_texte2[mot])
        else:
            for synonyme in mots_avec_synonymes1[mot]:
                if synonyme in poids_texte2:
                    mots_communs_avec_poids += (poids + poids_texte2[synonyme])
                    break

    pourcentage_similitude = (mots_communs_avec_poids / total_poids) * 100

    if pourcentage_similitude > seuil_triche:
        return True, pourcentage_similitude
    else:
        return False, pourcentage_similitude

"""
# Exemple d'utilisation
texte1 = "this is un exemple de texte pour la comparaison."
texte2 = "Ceci est un texte pour la comparaison, un exemple."

resultat, pourcentage = comparer_textes_ameliore(texte1, texte2)
if resultat:
    print(f"Triche détectée avec {pourcentage:.2f}% de similitude.")
else:
    print(f"Pas de triche détectée, {pourcentage:.2f}% de similitude.")
"""

def detecter_triche(fichier_audio, photo_ecran, seuil_detection=20, enregistrer=True):
    """
    Analyse deux sources de données, un fichier audio et une photo d'écran, pour détecter des similarités qui pourraient
    indiquer une triche. La fonction extrait les textes des deux sources, les compare, et enregistre les résultats dans
    un fichier si le pourcentage de similitude dépasse un seuil donné ou si l'enregistrement est explicitement demandé.

    Args:
    fichier_audio (str): Chemin vers le fichier audio à analyser.
    photo_ecran (str): Chemin vers l'image de l'écran à analyser.
    seuil_detection (int, optional): Seuil de pourcentage de similitude pour considérer la présence de triche. Par défaut à 20.
    enregistrer (bool, optional): Si True, enregistre les résultats dans un fichier même si le seuil n'est pas atteint. Par défaut à True.

    Returns:
    None: La fonction ne retourne rien mais écrit dans un fichier 'resultats_triche.txt' selon les conditions spécifiées.

    Effets secondaires:
    - Ecriture dans un fichier 'resultats_triche.txt' qui accumule les résultats des analyses au fil des appels.
    - Extraction de texte à partir des fichiers multimédias, qui peut être gourmande en ressources selon la taille des fichiers.
    """
    # Extraire le texte de la photo de l'écran
    texte_photo_ecran = extract_filter_and_remove_duplicates(photo_ecran)

    # Extraire le texte du fichier audio
    texte_fichier_audio = convert_audio_to_text(fichier_audio)

    # Comparer les textes
    resultat, pourcentage = comparer_textes_ameliore(texte_photo_ecran, texte_fichier_audio)

    # Écrire le résultat dans un fichier texte uniquement si le seuil est dépassé ou égal
    if pourcentage >= seuil_detection:
        with open("resultats_triche.txt", "a") as fichier_resultats:
            fichier_resultats.write("==== Traitement ====\n")
            fichier_resultats.write(f"Texte extrait de la photo de l'écran:\n{texte_photo_ecran}\n")
            fichier_resultats.write(f"Texte extrait du fichier audio:\n{texte_fichier_audio}\n")
            if resultat:
                fichier_resultats.write(f"Triche détectée avec {pourcentage:.2f}% de similitude.\n")
            else:
                fichier_resultats.write(f"Pas de triche détectée, {pourcentage:.2f}% de similitude.\n")
            fichier_resultats.write("==== Fin du traitement ====\n\n")
    elif enregistrer:
        # Si le seuil n'est pas dépassé mais l'enregistrement est demandé
        with open("resultats_triche.txt", "a") as fichier_resultats:
            fichier_resultats.write("==== Traitement ====\n")
            fichier_resultats.write(f"Texte extrait de la photo de l'écran:\n{texte_photo_ecran}\n")
            fichier_resultats.write(f"Texte extrait du fichier audio:\n{texte_fichier_audio}\n")
            fichier_resultats.write("==== Fin du traitement ====\n\n")

"""
# Exemple d'utilisation
fichier_audio = "test_audio_fr.mp3"
photo_ecran = "image_text.jpg"
detecter_triche(fichier_audio, photo_ecran)
"""